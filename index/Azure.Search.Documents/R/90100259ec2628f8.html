<!DOCTYPE html>
<html><head><title>LexicalTokenizer</title><link rel="stylesheet" href="../../styles.css"/><script src="../../scripts.js"></script></head><body onload="ro();">
<div class="rH">10 types derived from LexicalTokenizer</div><div class="rA">Azure.Search.Documents (10)</div><div class="rG" id="Azure.Search.Documents"><div class="rF"><div class="rN">Generated\Models\ClassicTokenizer.cs (1)</div>
<a href="../Generated/Models/ClassicTokenizer.cs.html#13"><b>13</b>public partial class ClassicTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\EdgeNGramTokenizer.cs (1)</div>
<a href="../Generated/Models/EdgeNGramTokenizer.cs.html#15"><b>15</b>public partial class EdgeNGramTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\KeywordTokenizer.cs (1)</div>
<a href="../Generated/Models/KeywordTokenizer.cs.html#13"><b>13</b>public partial class KeywordTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\LuceneStandardTokenizer.cs (1)</div>
<a href="../Generated/Models/LuceneStandardTokenizer.cs.html#13"><b>13</b>public partial class LuceneStandardTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\MicrosoftLanguageStemmingTokenizer.cs (1)</div>
<a href="../Generated/Models/MicrosoftLanguageStemmingTokenizer.cs.html#13"><b>13</b>public partial class MicrosoftLanguageStemmingTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\MicrosoftLanguageTokenizer.cs (1)</div>
<a href="../Generated/Models/MicrosoftLanguageTokenizer.cs.html#13"><b>13</b>public partial class MicrosoftLanguageTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\NGramTokenizer.cs (1)</div>
<a href="../Generated/Models/NGramTokenizer.cs.html#15"><b>15</b>public partial class NGramTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\PathHierarchyTokenizer.cs (1)</div>
<a href="../Generated/Models/PathHierarchyTokenizer.cs.html#13"><b>13</b>public partial class PathHierarchyTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\PatternTokenizer.cs (1)</div>
<a href="../Generated/Models/PatternTokenizer.cs.html#13"><b>13</b>public partial class PatternTokenizer : <i>LexicalTokenizer</i></a>
</div>
<div class="rF"><div class="rN">Generated\Models\UaxUrlEmailTokenizer.cs (1)</div>
<a href="../Generated/Models/UaxUrlEmailTokenizer.cs.html#13"><b>13</b>public partial class UaxUrlEmailTokenizer : <i>LexicalTokenizer</i></a>
</div>
</div>
<div class="rH">2 instantiations of LexicalTokenizer</div><div class="rA">Azure.Search.Documents (2)</div><div class="rG" id="Azure.Search.Documents"><div class="rF"><div class="rN">Generated\Models\LexicalTokenizer.Serialization.cs (1)</div>
<a href="../Generated/Models/LexicalTokenizer.Serialization.cs.html#60"><b>60</b>return new <i>LexicalTokenizer</i>(odataType, name);</a>
</div>
<div class="rF"><div class="rN">Models\SearchModelFactory.cs (1)</div>
<a href="../Models/SearchModelFactory.cs.html#95"><b>95</b>new <i>LexicalTokenizer</i>(oDataType, name);</a>
</div>
</div>
<div class="rH">15 references to LexicalTokenizer</div><div class="rA">Azure.Search.Documents (11)</div><div class="rG" id="Azure.Search.Documents"><div class="rF"><div class="rN">Generated\Models\LexicalTokenizer.Serialization.cs (1)</div>
<a href="../Generated/Models/LexicalTokenizer.Serialization.cs.html#25"><b>25</b>internal static <i>LexicalTokenizer</i> DeserializeLexicalTokenizer(JsonElement element)</a>
</div>
<div class="rF"><div class="rN">Generated\Models\SearchIndex.cs (1)</div>
<a href="../Generated/Models/SearchIndex.cs.html#33"><b>33</b>internal SearchIndex(string name, IList&lt;SearchField&gt; Fields, IList&lt;ScoringProfile&gt; scoringProfiles, string defaultScoringProfile, CorsOptions corsOptions, IList&lt;SearchSuggester&gt; suggesters, IList&lt;LexicalAnalyzer&gt; analyzers, IList&lt;<i>LexicalTokenizer</i>&gt; tokenizers, IList&lt;TokenFilter&gt; tokenFilters, IList&lt;CharFilter&gt; charFilters, SearchResourceEncryptionKey encryptionKey, SimilarityAlgorithm similarity, string Etag)</a>
</div>
<div class="rF"><div class="rN">Generated\Models\SearchIndex.Serialization.cs (5)</div>
<a href="../Generated/Models/SearchIndex.Serialization.cs.html#79"><b>79</b>foreach (<i>var</i> item in Tokenizers)</a>
<a href="../Generated/Models/SearchIndex.Serialization.cs.html#139"><b>139</b>Optional&lt;IList&lt;<i>LexicalTokenizer</i>&gt;&gt; tokenizers = default;</a>
<a href="../Generated/Models/SearchIndex.Serialization.cs.html#229"><b>229</b>List&lt;<i>LexicalTokenizer</i>&gt; array = new List&lt;<i>LexicalTokenizer</i>&gt;();</a>
<a href="../Generated/Models/SearchIndex.Serialization.cs.html#232"><b>232</b>array.Add(<i>LexicalTokenizer</i>.DeserializeLexicalTokenizer(item));</a>
</div>
<div class="rF"><div class="rN">Indexes\Models\SearchIndex.cs (3)</div>
<a href="../Indexes/Models/SearchIndex.cs.html#39"><b>39</b>Tokenizers = new ChangeTrackingList&lt;<i>LexicalTokenizer</i>&gt;();</a>
<a href="../Indexes/Models/SearchIndex.cs.html#62"><b>62</b>Tokenizers = new ChangeTrackingList&lt;<i>LexicalTokenizer</i>&gt;();</a>
<a href="../Indexes/Models/SearchIndex.cs.html#160"><b>160</b>public IList&lt;<i>LexicalTokenizer</i>&gt; Tokenizers { get; }</a>
</div>
<div class="rF"><div class="rN">Models\SearchModelFactory.cs (1)</div>
<a href="../Models/SearchModelFactory.cs.html#92"><b>92</b>public static <i>LexicalTokenizer</i> LexicalTokenizer(</a>
</div>
</div>
<div class="rA">Azure.Search.Documents.Tests (4)</div><div class="rG" id="Azure.Search.Documents.Tests"><div class="rF"><div class="rN">Models\KeywordTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/KeywordTokenizerTests.cs.html#33"><b>33</b>KeywordTokenizer sut = <i>LexicalTokenizer</i>.DeserializeLexicalTokenizer(jsonDoc.RootElement) as KeywordTokenizer;</a>
</div>
<div class="rF"><div class="rN">Models\LuceneStandardTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/LuceneStandardTokenizerTests.cs.html#32"><b>32</b>LuceneStandardTokenizer sut = <i>LexicalTokenizer</i>.DeserializeLexicalTokenizer(jsonDoc.RootElement) as LuceneStandardTokenizer;</a>
</div>
<div class="rF"><div class="rN">Models\PathHierarchyTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/PathHierarchyTokenizerTests.cs.html#35"><b>35</b>PathHierarchyTokenizer sut = <i>LexicalTokenizer</i>.DeserializeLexicalTokenizer(jsonDoc.RootElement) as PathHierarchyTokenizer;</a>
</div>
<div class="rF"><div class="rN">Models\PatternTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/PatternTokenizerTests.cs.html#25"><b>25</b>PatternTokenizer actual = <i>LexicalTokenizer</i>.DeserializeLexicalTokenizer(doc.RootElement) as PatternTokenizer;</a>
</div>
</div>
</body></html>