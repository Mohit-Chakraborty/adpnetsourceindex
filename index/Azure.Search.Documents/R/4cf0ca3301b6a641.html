<!DOCTYPE html>
<html><head><title>DeserializeLexicalTokenizer</title><link rel="stylesheet" href="../../styles.css"/><script src="../../scripts.js"></script></head><body onload="ro();">
<div class="rH">5 references to DeserializeLexicalTokenizer</div><div class="rA">Azure.Search.Documents (1)</div><div class="rG" id="Azure.Search.Documents"><div class="rF"><div class="rN">Generated\Models\SearchIndex.Serialization.cs (1)</div>
<a href="../Generated/Models/SearchIndex.Serialization.cs.html#232"><b>232</b>array.Add(LexicalTokenizer.<i>DeserializeLexicalTokenizer</i>(item));</a>
</div>
</div>
<div class="rA">Azure.Search.Documents.Tests (4)</div><div class="rG" id="Azure.Search.Documents.Tests"><div class="rF"><div class="rN">Models\KeywordTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/KeywordTokenizerTests.cs.html#33"><b>33</b>KeywordTokenizer sut = LexicalTokenizer.<i>DeserializeLexicalTokenizer</i>(jsonDoc.RootElement) as KeywordTokenizer;</a>
</div>
<div class="rF"><div class="rN">Models\LuceneStandardTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/LuceneStandardTokenizerTests.cs.html#32"><b>32</b>LuceneStandardTokenizer sut = LexicalTokenizer.<i>DeserializeLexicalTokenizer</i>(jsonDoc.RootElement) as LuceneStandardTokenizer;</a>
</div>
<div class="rF"><div class="rN">Models\PathHierarchyTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/PathHierarchyTokenizerTests.cs.html#35"><b>35</b>PathHierarchyTokenizer sut = LexicalTokenizer.<i>DeserializeLexicalTokenizer</i>(jsonDoc.RootElement) as PathHierarchyTokenizer;</a>
</div>
<div class="rF"><div class="rN">Models\PatternTokenizerTests.cs (1)</div>
<a href="../../Azure.Search.Documents.Tests/Models/PatternTokenizerTests.cs.html#25"><b>25</b>PatternTokenizer actual = LexicalTokenizer.<i>DeserializeLexicalTokenizer</i>(doc.RootElement) as PatternTokenizer;</a>
</div>
</div>
</body></html>